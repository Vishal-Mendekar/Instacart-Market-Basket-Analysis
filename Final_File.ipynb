{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNZuLqFw3oeb",
        "colab_type": "text"
      },
      "source": [
        "# First Function Description\n",
        "\n",
        "1. This function takes 2 inputs.\n",
        "\n",
        "2. First is a small dataframe for a specific user, second is the test point in which we have to give predictions\n",
        "\n",
        "3. Since we have all the columns in given dataframe. So we create multiple new dataframe each with their unique features based on column values of given small dataframe.\n",
        "\n",
        "4. Later on in the function we merge all this dataframe created. The given dataframe has reordered column too which is our true label so we get reordered features too. \n",
        "\n",
        "5. Our test_point do not have the reordered column as we have to predict on it.\n",
        "\n",
        "6. We merge our given dataframe few columns with the merged features dataframe created.\n",
        "\n",
        "7. Now we drop the 'reordered' and merge this dataframe with the test point. So now we have all the features in test point too.\n",
        "\n",
        "8. Now we load our best model and finally predict the dataframe as well as test point.\n",
        "\n",
        "9. Now we add the results as column in dataframe and we create a dictionary with this dataframe such that we have keys as the order_id and values is the list of products for the specific order_id and user_id. This is our final prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oldsVZcx5IAo",
        "colab_type": "text"
      },
      "source": [
        "#There maybe several question \n",
        "\n",
        "<b>[Q].</b> Why we need dataframe and test point as input in function and not just the test point?\n",
        "\n",
        "<b>[A].</b> 1.As per the problem definition we have to predict the products which can be reordered by user. And if we get a new user there is no point of predicting products to be reordered. As user never ordered before.\n",
        "\n",
        "2. The dataframe contains previous order history of new user. Also it has reorderd column which is the label here. So with this dataframe we are able to build the features and then we merge this features dataframe with the final test point and we get prediction.\n",
        "\n",
        "<b>[Q].</b> Why we have the code for dictionary. And why do we return values of this dictionary?\n",
        "\n",
        "<b>[A].</b> The problem we have is to recommend a problem. So its a recommendation problem achieved through classification technique. Here for each order_id and product_id pair the model predicts 0 or 1. And then we create a dictionary and using order_id as key we create list of all products to be reorderd and set it as the value of dictionary for that specific key.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBEpqudmhhMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "def predict_function(df, test_point):\n",
        "    user_df = pd.DataFrame()\n",
        "    user_df['max_number_of_orders'] = df.groupby(by='user_id')\n",
        "    user_df['order_number'].aggregate('max').astype(np.uint8)\n",
        "    user_df['mean_number_of_orders'] = df.groupby(by='user_id')['order_number'].aggregate('mean').astype(np.uint8)\n",
        "    user_df['min_number_of_orders'] = df.groupby(by='user_id')\n",
        "    user_df['order_number'].aggregate('min').astype(np.uint8)\n",
        "\n",
        "    # Features Using Average Products\n",
        "    max_order = pd.DataFrame()\n",
        "    average_products= pd.DataFrame()\n",
        "    max_order['total_products_per_order'] = df.groupby(by=['user_id', 'order_id'])\n",
        "    max_order['product_id'].aggregate('count').astype(np.uint8)\n",
        "    average_products['average_user_product'] = max_order.groupby(by=['user_id'])\n",
        "    average_products['total_products_per_order'].aggregate('mean').astype(np.float16)\n",
        "\n",
        "    # Features Using Day Of Week\n",
        "    day_of_week = pd.DataFrame()\n",
        "    day_of_week['max_order_day'] = df.groupby(by=['user_id'])['order_dow'].aggregate(lambda x : stats.mode(x)[0]).astype(np.uint8)\n",
        "    day_of_week = day_of_week.reset_index()\n",
        "\n",
        "    # Features Using Hour of Day\n",
        "    hour_of_day = pd.DataFrame()\n",
        "    hour_of_day['max_order_by_hour'] = df.groupby(by=['user_id'])['order_hour_of_day'].aggregate(lambda x : stats.mode(x)[0]).astype(np.uint8)\n",
        "    hour_of_day = hour_of_day.reset_index()\n",
        "\n",
        "    # Reorder Features\n",
        "    reorder_by_user = pd.DataFrame()\n",
        "    reorder_by_user['total_reorders'] = df[df['reordered']==1].groupby('user_id')['reordered'].aggregate('count').astype(np.uint8)\n",
        "    reorder_by_user['total_non_reorders'] = df[df['reordered']==0].groupby('user_id')['reordered'].aggregate('count').astype(np.uint8)\n",
        "    reorder_by_user['reorder_ratio'] =reorder_by_user['total_reorders']/(reorder_by_user['total_reorders'] +\n",
        "    reorder_by_user['total_non_reorders']).astype(np.float16)\n",
        "\n",
        "    # Merging All The Features\n",
        "    user_df = pd.merge(user_df, average_products, on='user_id', how='left')\n",
        "    user_df = pd.merge(user_df, day_of_week, on='user_id', how='left')\n",
        "    user_df = pd.merge(user_df, hour_of_day, on='user_id', how='left')\n",
        "    user_df = pd.merge(user_df, reorder_by_user, on='user_id', how='left')\n",
        "\n",
        "    # Deleting the intermmediate dataframes and handling the NaN values if exists\n",
        "    del average_products, day_of_week, hour_of_day, reorder_by_user, prior\n",
        "    user_df = user_df.fillna(0)\n",
        "\n",
        "    # Creating Product Dataframe\n",
        "    product_df = pd.DataFrame()\n",
        "    product_df['times_product_ordered'] = df.groupby(by='product_id')\n",
        "    product_df['order_id'].aggregate('count').astype(np.uint16)\n",
        "\n",
        "    # Reorder DataFrame Features\n",
        "    reorder_products = pd.DataFrame()\n",
        "    reorder_products['product_reorder_ratio'] = df.groupby('product_id')['reordered'].aggregate('mean').astype(np.float16)\n",
        "    reorder_products['product_not_reorder_time'] = df[df['reordered']==0].groupby('product_id')['reordered'].aggregate('count').astype(np.uint8)\n",
        "\n",
        "    # Add to cart features\n",
        "    add_to_cart = pd.DataFrame()\n",
        "    add_to_cart['average_product_cart_position'] = df.groupby(by='product_id')['add_to_cart_order'].aggregate('mean').astype(np.float16)\n",
        "    add_to_cart['late_product_cart_position'] = df.groupby(by='product_id')['add_to_cart_order'].aggregate('max').astype(np.float16)\n",
        "    add_to_cart['early_product_cart_position'] = df.groupby(by='product_id')['add_to_cart_order'].aggregate('min').astype(np.float16)\n",
        "\n",
        "    # Day Of Week Features\n",
        "    dow_product = pd.DataFrame()\n",
        "    dow_product['average_product_order_day'] = df.groupby(by='product_id')['order_dow'].aggregate('mean').astype(np.float16)\n",
        "    dow_product['late_product_order_day'] = df.groupby(by='product_id')['order_dow'].aggregate('max').astype(np.float16)\n",
        "    dow_product['early_product_order_day'] = df.groupby(by='product_id')['order_dow'].aggregate('min').astype(np.float16)\n",
        "\n",
        "    # Order Hour Of Day Features\n",
        "    order_hour_of_day_product = pd.DataFrame()\n",
        "    order_hour_of_day_product['average_product_hour'] = df.groupby(by='product_id')['order_hour_of_day'].aggregate('mean').astype(np.float16)\n",
        "    order_hour_of_day_product['late_product_hour'] = df.groupby(by='product_id')['order_hour_of_day'].aggregate('max').astype(np.float16)\n",
        "    order_hour_of_day_product['early_product_hour'] = df.groupby(by='product_id')['order_hour_of_day'].aggregate('min').astype(np.float16)\n",
        "\n",
        "    # Merging all the dataframes\n",
        "    product_df = pd.merge(product_df, reorder_products, on='product_id', how='left')\n",
        "    product_df = pd.merge(product_df, add_to_cart, on='product_id', how='left')\n",
        "    product_df = pd.merge(product_df, dow_product, on='product_id', how='left')\n",
        "    product_df = pd.merge(product_df, order_hour_of_day_product, on='product_id', how='left')\n",
        "\n",
        "    # User Product Dataframe\n",
        "    user_product_df = pd.DataFrame()\n",
        "    user_product_df['times_product_by_user'] = df.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').astype(np.uint8)\n",
        "    user_product_df = user_product_df.reset_index()\n",
        "\n",
        "    # Products Bought DataFrame\n",
        "    product_bought = pd.DataFrame()\n",
        "    product_bought['times_bought'] = df.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count').astype(np.uint8)\n",
        "    product_bought['earliest_order_position'] = df.groupby(by=['user_id', 'product_id'])['order_number'].aggregate('min').astype(np.uint8)\n",
        "    product_bought = product_bought.reset_index()\n",
        "\n",
        "    # Order By User DataFrame\n",
        "    order_by_user = pd.DataFrame()\n",
        "    order_by_user['total_orders_by_user'] = df.groupby('user_id')['order_number'].aggregate('max').astype(np.uint16)\n",
        "    order_by_user = order_by_user.reset_index()\n",
        "\n",
        "    merged_user_order = pd.merge(order_by_user, product_bought, how='right', on='user_id')\n",
        "    merged_user_order['order_range'] = merged_user_order['total_orders_by_user'] - merged_user_order['earliest_order_position'] + 1\n",
        "\n",
        "    user_product_merged_df = pd.merge(merged_user_order, user_product_df, on=['user_id', 'product_id'], how='left')\n",
        "    user_product_merged_df['user_pro_reorder_ratio'] = user_product_merged_df['times_bought'] / user_product_merged_df['order_range']\n",
        "    user_product_merged_df = user_product_merged_df.drop(['total_orders_by_user','order_range','times_product_by_user','earliest_order_position','times_bought'],axis=1)\n",
        "    product_bought.drop(['earliest_order_position'],axis=1, inplace=True)\n",
        "    product_bought = pd.merge(product_bought, user_product_merged_df, on=['user_id','product_id'], how='left')\n",
        "    \n",
        "    prior_order_df['order_number_back'] = (df.groupby(by=['user_id'])['order_number'].transform(max) - prior_order_df['order_number'] + 1).astype(np.uint8)\n",
        "    temp = prior_order_df.loc[prior_order_df['order_number_back'] <= 10]\n",
        "\n",
        "    recent_orders = pd.DataFrame()\n",
        "    recent_orders['recent_ten'] = (temp.groupby(by=['user_id', 'product_id'])['order_id'].aggregate('count')).astype(np.uint16)\n",
        "    recent_orders['recent_ten_ratio'] = (recent_orders['recent_ten'] / 10.0).astype(np.float16)\n",
        "\n",
        "    product_bought = pd.merge(product_bought, recent_orders, on=['user_id', 'product_id'], how='left')\n",
        "    product_bought = product_bought.fillna(0)\n",
        "    del temp, recent_orders\n",
        "\n",
        "    final_data = pd.merge(product_bought, user_df, on='user_id', how='left')\n",
        "    final_data = pd.merge(final_data, product_df, on='product_id', how='left')\n",
        "    del product_bought, product_df, user_df\n",
        "\n",
        "    df_new = test_point['user_id', 'order_id']\n",
        "    \n",
        "    final_data_new = pd.merge(final_data, df, on='user_id', how='left')\n",
        "    final_data_new = final_data_new.drop('reordered',axis=1)\n",
        "    final_data_new = pd.merge(final_data_new, df_new, on='user_id', how='left')\n",
        "\n",
        "    final_data_train = final_data_new.set_index(['user_id', 'product_id'])\n",
        "    final_data_train.drop(['order_id'], axis=1, inplace=True)\n",
        "\n",
        "    model = pickle.load(open('/content/drive/My Drive/Sequence_To_Sequence/tuned_lgb.pkl','rb'))\n",
        "    \n",
        "    final_data_train['reordered'] = (model.predict_proba(final_data_train)[:, 1] >=0.21).astype('int')\n",
        "\n",
        "    final_test_data = final_data_train[['product_id', 'user_id', 'prediction']]\n",
        "    \n",
        "    user_product = dict()\n",
        "    for row in tqdm(final_test_data.itertuples()):\n",
        "        if row.prediction== 1:\n",
        "            try:\n",
        "                user_product[row.order_id] += ' ' + str(row.product_id)\n",
        "            except:\n",
        "                user_product[row.order_id] = str(row.product_id)\n",
        "\n",
        "    for order in final_df.order_id:\n",
        "        if order not in user_product:\n",
        "            user_product[order] = 'None'\n",
        "\n",
        "    return user_product.values()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLnLrl2lCStv",
        "colab_type": "text"
      },
      "source": [
        "# Second Function Description\n",
        "\n",
        "1. The function takes a test_point as input. Now we look for the datapoint with same user_id, product_id, order_id.\n",
        "\n",
        "2. If the test_point exists in the train data we get its label.\n",
        "\n",
        "3. Now we load the model and predict on the test_point and calculate the f1_score with the true label.\n",
        "\n",
        "4. If the test_point doesn't exists in the train data so we don't have the true label and we can't get the f1_score so we return the message <b>\"Since the test point doesn't exits in train data so we don't have real label so we can't return metrics score.\".</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTOrorhCtiLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_metrics(test_point):\n",
        "\n",
        "    model = pickle.load(open('/content/drive/My Drive/Sequence_To_Sequence/tuned_lgb.pkl','rb'))\n",
        "    \n",
        "    order_id = test_point['order_id'].values\n",
        "    product_id = test_point['product_id'].values\n",
        "    user_id = test_point['user_id'].values\n",
        "\n",
        "    train_data = pickle.load(open('/content/drive/My Drive/Instacart Analysis/final_data_trainn.pkl','rb'))\n",
        "    true_label = train_data.loc[((train_data['order_id']==order_id) and (train_data['product_id']==product_id) and (train_data['user_id']==user_id)), ['reordered']]\n",
        "\n",
        "    if(true_label!='None'):\n",
        "        prediction = (model.predict_proba(final_data_train)[:, 1] >=0.21).astype('int')\n",
        "        return f1_score(prediction, true_label)\n",
        "    else:\n",
        "        return \"Since the test point doesn't exits in train data so we don't have real label so we can't return metrics score.\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLrnkj3sBpji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}